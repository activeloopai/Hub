{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hub.utils import Timer\n",
    "from hub import Dataset\n",
    "from memory_profiler import memory_usage\n",
    "import asyncio\n",
    "import psutil\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Monitoring Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def network_monitor(check_finish, sample_frequency=1):\n",
    "    samples = []\n",
    "    prev_bytes = None\n",
    "    while True:\n",
    "        stats = psutil.net_io_counters()\n",
    "        if prev_bytes is not None:\n",
    "            samples.append((time.time(), stats.bytes_recv - prev_bytes))\n",
    "        prev_bytes = stats.bytes_recv\n",
    "        await asyncio.sleep(sample_frequency)\n",
    "        if check_finish():\n",
    "            return samples\n",
    "\n",
    "async def network_monitor_call(f):\n",
    "    is_finished = False\n",
    "    check_finish = lambda: is_finished\n",
    "    task = asyncio.create_task(network_monitor(check_finish))\n",
    "    await asyncio.to_thread(f)\n",
    "    is_finished = True\n",
    "    await task\n",
    "    return task.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_runner(params):\n",
    "    run_function, setup_function, setup_params = params\n",
    "    params = setup_function(*setup_params)\n",
    "    begin = time.time()\n",
    "    run_function(params)\n",
    "    end = time.time()\n",
    "    return end - begin\n",
    "\n",
    "def memory_runner(params):\n",
    "    run_function, setup_function, setup_params = params\n",
    "    params = setup_function(*setup_params)\n",
    "    baseline = memory_usage()\n",
    "    usage = memory_usage((run_function, (params,)))\n",
    "    return (max(baseline), max(usage))\n",
    "\n",
    "async def network_runner(params):\n",
    "    run_function, setup_function, setup_params = params\n",
    "    params = setup_function(*setup_params)\n",
    "    return await network_monitor_call(lambda: run_function(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Full Dataset Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_access_hub_full import benchmark_access_hub_full_setup, benchmark_access_hub_full_run\n",
    "access_full_suite = [(benchmark_access_hub_full_run, benchmark_access_hub_full_setup, (dset,)) for dset in ['activeloop/mnist']]\n",
    "\n",
    "hub_full_times = list(map(time_runner, access_full_suite))\n",
    "hub_full_mem_usages = list(map(memory_runner, access_full_suite))\n",
    "hub_full_net_usages = [await network_runner(params) for params in access_full_suite]\n",
    "\n",
    "print(hub_full_times)\n",
    "print(hub_full_mem_usages)\n",
    "print(hub_full_net_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Random Slice Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_access_hub_slice import benchmark_access_hub_slice_setup, benchmark_access_hub_slice_run\n",
    "access_slice_suite = [(benchmark_access_hub_slice_run, benchmark_access_hub_slice_setup, t) for t in [('activeloop/mnist', (0, 256)), ('activeloop/mnist', (2048, 2048+256))]]\n",
    "\n",
    "hub_slice_times = list(map(time_runner, access_slice_suite))\n",
    "hub_slice_mem_usages = list(map(memory_runner, access_slice_suite))\n",
    "hub_slice_net_usages = [await network_runner(params) for params in access_slice_suite]\n",
    "\n",
    "print(hub_slice_times)\n",
    "print(hub_slice_mem_usages)\n",
    "print(hub_slice_net_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_compress_hub import benchmark_compress_hub_setup, benchmark_compress_hub_run\n",
    "hub_compress_suite = [(benchmark_compress_hub_run, benchmark_compress_hub_setup, t) for t in [(32,)]]\n",
    "\n",
    "hub_compress_times = list(map(time_runner, hub_compress_suite))\n",
    "hub_compress_mem_usages = list(map(memory_runner, hub_compress_suite))\n",
    "\n",
    "print(hub_compress_times)\n",
    "print(hub_compress_mem_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pillow Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_compress_pillow import benchmark_compress_pillow_setup, benchmark_compress_pillow_run\n",
    "pillow_compress_suite = [(benchmark_compress_pillow_run, benchmark_compress_pillow_setup, t) for t in [(32,)]]\n",
    "\n",
    "pillow_compress_times = list(map(time_runner, pillow_compress_suite))\n",
    "pillow_compress_mem_usages = list(map(memory_runner, pillow_compress_suite))\n",
    "\n",
    "print(pillow_compress_times)\n",
    "print(pillow_compress_mem_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Local Dataset Iteration - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_iterate_hub_local_pytorch import benchmark_iterate_hub_local_pytorch_setup, benchmark_iterate_hub_local_pytorch_run\n",
    "iterate_local_pytorch_suite = [(benchmark_iterate_hub_local_pytorch_run, benchmark_iterate_hub_local_pytorch_setup, t) for t in [('MNIST', 'train', 128, 128)]]\n",
    "\n",
    "hub_iterate_local_pytorch_times = list(map(time_runner, iterate_local_pytorch_suite))\n",
    "hub_iterate_local_pytorch_mem_usages = list(map(memory_runner, iterate_local_pytorch_suite))\n",
    "hub_iterate_local_pytorch_net_usages = [await network_runner(params) for params in iterate_local_pytorch_suite]\n",
    "\n",
    "print(hub_iterate_local_pytorch_times)\n",
    "print(hub_iterate_local_pytorch_mem_usages)\n",
    "print(hub_iterate_local_pytorch_net_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Local Dataset Iteration - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_iterate_hub_local_tensorflow import benchmark_iterate_hub_local_tensorflow_setup, benchmark_iterate_hub_local_tensorflow_run\n",
    "iterate_local_tensorflow_suite = [(benchmark_iterate_hub_local_tensorflow_run, benchmark_iterate_hub_local_tensorflow_setup, t) for t in [('mnist', 'train', 128, 128)]]\n",
    "\n",
    "hub_iterate_local_tensorflow_times = list(map(time_runner, iterate_local_tensorflow_suite))\n",
    "hub_iterate_local_tensorflow_mem_usages = list(map(memory_runner, iterate_local_tensorflow_suite))\n",
    "hub_iterate_local_tensorflow_net_usages = [await network_runner(params) for params in iterate_local_tensorflow_suite]\n",
    "\n",
    "print(hub_iterate_local_tensorflow_times)\n",
    "print(hub_iterate_local_tensorflow_mem_usages)\n",
    "print(hub_iterate_local_tensorflow_net_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Dataset Iteration - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_iterate_hub_pytorch import benchmark_iterate_hub_pytorch_setup, benchmark_iterate_hub_pytorch_run\n",
    "iterate_pytorch_suite = [(benchmark_iterate_hub_pytorch_run, benchmark_iterate_hub_pytorch_setup, t) for t in [('activeloop/mnist', 128, 128)]]\n",
    "\n",
    "hub_iterate_pytorch_times = list(map(time_runner, iterate_pytorch_suite))\n",
    "hub_iterate_pytorch_mem_usages = list(map(memory_runner, iterate_pytorch_suite))\n",
    "hub_iterate_pytorch_net_usages = [await network_runner(params) for params in iterate_pytorch_suite]\n",
    "\n",
    "print(hub_iterate_pytorch_times)\n",
    "print(hub_iterate_pytorch_mem_usages)\n",
    "print(hub_iterate_pytorch_net_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hub Dataset Iteration - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_iterate_hub_tensorflow import benchmark_iterate_hub_tensorflow_setup, benchmark_iterate_hub_tensorflow_run\n",
    "iterate_tensorflow_suite = [(benchmark_iterate_hub_tensorflow_run, benchmark_iterate_hub_tensorflow_setup, t) for t in [('activeloop/mnist', 128, 128)]]\n",
    "\n",
    "hub_iterate_tensorflow_times = list(map(time_runner, iterate_tensorflow_suite))\n",
    "hub_iterate_tensorflow_mem_usages = list(map(memory_runner, iterate_tensorflow_suite))\n",
    "hub_iterate_tensorflow_net_usages = [await network_runner(params) for params in iterate_tensorflow_suite]\n",
    "\n",
    "print(hub_iterate_tensorflow_times)\n",
    "print(hub_iterate_tensorflow_mem_usages)\n",
    "print(hub_iterate_tensorflow_net_usages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Benchmark Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to your favourite file format here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
